{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+3\"><strong>Extract, Transform, Load</strong></font>\n",
    "\n",
    "In Data Science and Data Engineering, the process of taking data from a source, changing it, and then loading it into a database is called **ETL**, which is short for **extract, transform, load**. ETL tends to be more programming-intensive than other data science tasks like visualization, so we'll also spend time in this lesson exploring Python as an **object-oriented programming** language. Specifically, we'll create our own Python **class** to contain our ETL processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "#from teaching_tools.ab_test.reset import Reset\n",
    "#from pymongo import MongoClient\n",
    "\n",
    "#r = Reset()\n",
    "#r.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(host=\"localhost\", port=27017)\n",
    "db = client[\"wqu-abtest\"]\n",
    "ds_app = db[\"ds-applicants\"]\n",
    "print(\"client\", type(client))\n",
    "print(\"ds_app:\", type(ds_app))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract: Developing the Hypothesis\n",
    "Now that we've connected to the data, we need to pull out the information we need. One aspect of our applicant pool that we didn't explore in the last lesson is how many applicants actually complete the DS Lab admissions quiz."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the [`aggregate`](https://pymongo.readthedocs.io/en/stable/api/pymongo/collection.html#pymongo.collection.Collection.aggregate) method to calculate the number of applicants that completed and did not complete the admissions quiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ds_app.aggregate([{\"$group\":\n",
    "                            {\"_id\": \"$admissionsQuiz\",\n",
    "                             \"count\": {\"$count\": {} }}}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many applicants complete the admission quiz?\n",
    "\n",
    "result = ds_app.aggregate([{\"$group\": {\"_id\": \"$admissionsQuiz\",\n",
    "                                       \"count\": {\"$count\":{}}}}])\n",
    "for r in result:\n",
    "    if r[\"_id\"] == \"complete\":\n",
    "        complete = r[\"count\"]\n",
    "    else:\n",
    "        incomplete = r[\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Complete quiz:\", complete)\n",
    "print(\"Did not complete quiz:\", incomplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proportion of new user that have not complete the quiz\n",
    "total = complete + incomplete\n",
    "prop_incompete = incomplete / complete\n",
    "print(\"Proportion of users who do not complete the admission quiz:\",\n",
    "      round(prop_incompete, 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know that around a quarter of the applicants don't complete the admissions quiz, is there anything we can do improve the completion rate? \n",
    "\n",
    "A **hypothesis** is an informed guess about what we think is going to happen in an experiment. We probably hope that whatever we're trying out is going to work, but it's important to maintain a healthy degree of skepticism. Science experiments are designed to demonstrate what *does* work, not what doesn't, so we always start out by assuming that whatever we're about to do won't make a difference (even if we hope it will). The idea that an experimental intervention won't change anything is called a **null hypothesis** ($H_0$), and every experiment either rejects the null hypothesis (meaning the intervention worked), or fails to reject the null hypothesis (meaning it didn't). \n",
    "\n",
    "The mirror image of the null hypothesis is called an **alternate hypothesis** ($H_a$), and it proceeds from the idea that whatever we're about to do actually *will* work. If I'm trying to figure out whether exercising is going to help me lose weight, the null hypothesis says that if I exercise, I won't lose any weight. The alternate hypothesis says that if I exercise, I will lose weight. \n",
    "\n",
    "It's important to keep both types of hypothesis in mind as you work through your experimental design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_hypothesis = \"\"\"\n",
    "There is no relationship between recieving an email and completing the admission quiz, i.e\n",
    "    Sending an email to 'no-quiz applicants' does not increase the rate of completion.\n",
    "\"\"\"\n",
    "alternate_hypothesis = \"\"\"\n",
    "There is a relationship between recieving an email and completing the admission quiz, i.e\n",
    "    Sending an email to 'no-quiz applicants' increases the rate of completion.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Null Hypothesis:\", null_hypothesis)\n",
    "print(\"Alternate Hypothesis:\", alternate_hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function that search 'ds_applicants' and return all the no-quiz applicants from a specific date\n",
    "collection = ds_app\n",
    "dat_string = '2022-05-04'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_by_date(collection, date_string):\n",
    "    #convert 'date_string' to a datetime object\n",
    "    start = pd.to_datetime(date_string, format='%Y-%m-%d')\n",
    "    # Offset start by 1 day\n",
    "    end = start + pd.DateOffset(days=1)\n",
    "    # Create pymongo query for no-quiz applicant b/t start and end\n",
    "    query = {\"createdAt\": {\"$gte\": start, \"$lt\": end}, \"admissionsQuiz\": \"incomplete\"}\n",
    "    #Query collection, get result\n",
    "    result = collection.find(query)\n",
    "    observations = list(result)\n",
    "\n",
    "    return observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = find_by_date(ds_app, date_string=\"2022-05-05\")\n",
    "print(\"observations type:\", type(observations))\n",
    "print(\"observations len:\", len(observations))\n",
    "observations[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform: Designing the Experiment\n",
    "Okay! Now that we've extracted the data we'll need for the experiment, it's time to get our hands dirty. \n",
    "\n",
    "The **transform** stage of ETL involves manipulating the data we just extracted. In this case, we're going to be figuring out which students didn't take the quiz, and assigning them to different experimental groups. To do that, we'll need to *transform* each document in the database by creating a new attribute for each record.\n",
    "\n",
    "Now we can split the students who didn't take the quiz into two groups: one that will receive a reminder email, and one that will not. Let's make another function that'll do that for us.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function `assign_to_groups` that takes a list of new user documents as input and adds two keys to each document. The first key should be `\"inExperiment\"`, and its value should always be `True`. The second key should be `\"group\"`, with half of the records in `\"email (treatment)\"` and the other half in `\"no email (control)\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_to_groups(observations):\n",
    "    #shuffle the observations\n",
    "    random.seed(42)\n",
    "    random.shuffle(observations)\n",
    "    #get index positions of item at observations and halfway point\n",
    "    idx = len(observations)\n",
    "\n",
    "    #Assign first half to control group\n",
    "    for doc in observations[idx:]:\n",
    "        doc[\"inExperiment\"] = True\n",
    "        doc[\"group\"] = \"email (control)\"\n",
    "    #Assign second half to treatment group\n",
    "    for doc in observations[idx:]:\n",
    "        doc[\"inExperiment\"] = True\n",
    "        doc[\"group\"] = \"email (treatment)\"\n",
    "\n",
    "    return observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_assigned = assign_to_groups(observations)\n",
    "\n",
    "print(\"observations_assigned type:\", type(observations_assigned))\n",
    "print(\"observations_assigned len:\", len(observations_assigned))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function `export_email` that takes a list of documents (like `observations_assigned`) as input, creates a DataFrame with the emails of all observations in the treatment group, and saves the DataFrame as a CSV file. Then use your function to create a CSV file in the current directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_treatment_emails(observations_assigned, directory=\".\"):\n",
    "     # Put `observations_assigned` docs into DataFrame\n",
    "    df = pd.DataFrame(observations_assigned)\n",
    "\n",
    "    # Add `\"tag\"` column\n",
    "    df[\"tag\"] = \"ab-test\"\n",
    "\n",
    "    # Create mask for treatment group only\n",
    "    mask = df[\"group\"] == \"email (treatment)\"\n",
    "\n",
    "    # Create filename with date\n",
    "    date_string = pd.Timestamp.now().strftime(format=\"%Y-%m-%d\")\n",
    "    filename = directory + \"/\" + date_string + \"_ab-test.csv\"\n",
    "\n",
    "    # Save DataFrame to directory (email and tag only)\n",
    "    df[mask][[\"email\", \"tag\"]].to_csv(filename, index=False)\n",
    "\n",
    "\n",
    "export_treatment_emails(observations_assigned=observations_assigned)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the first item in `observations_assigned` list to the variable `updated_applicant`. The assign that applicant's ID to the variable `applicant_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_applicant = observations_assigned[0]\n",
    "applicant_id = updated_applicant[\"_id\"]\n",
    "print(\"applicant type:\", type(updated_applicant))\n",
    "print(updated_applicant)\n",
    "print(\"applicant_id type:\", type(applicant_id))\n",
    "print(applicant_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `find_one` method together with the `applicant_id` from the previous task to locate the original record in the `\"ds-applicants\"` collection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find original record for `applicant_id`\n",
    "ds_app.find_one({\"_id\": applicant_id})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `update_one` method to update the record with the new information in `updated_applicant`. Once you're done, rerun your query from the previous task to see if the record has been updated. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ds_app.update_one(\n",
    "    filter={\"_id\": applicant_id},\n",
    "    update={\"$set\": updated_applicant}\n",
    ")\n",
    "print(\"result type:\", type(result))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Use the [`dir`](https://docs.python.org/3/library/functions.html#dir) function to inspect `result`. Once you see some of the attributes, try to access them. For instance, what does the `raw_result` attribute tell you about the success of your record update?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access methods and attributes using `dir`\n",
    "dir(result) #type(result)\n",
    "# Access `raw_result` attribute\n",
    "result.raw_result #\n",
    "#find original record of 'applicant_id'\n",
    "ds_app.find_one({\"_id\": applicant_id})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Create a function `update_applicants` that takes a list of document like as input, updates the corresponding documents in a collection, and returns a dictionary with the results of the update. Then use your function to update `\"ds-applicants\"` with `observations_assigned`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_applicants(collection, observations_assigned):\n",
    "    n = 0\n",
    "    n_modified = 0\n",
    "    #iterate through applicants\n",
    "    for doc in observations_assigned:\n",
    "        result = ds_app.update_one(\n",
    "            filter={\"_id\": doc[\"_id\"]},\n",
    "            update={\"$set\": doc}\n",
    "            )\n",
    "        #updated counter\n",
    "        n += result.matched_count\n",
    "        n_modified += result.modified_count\n",
    "    #create results\n",
    "    transaction_result = {\"n\": n, \"nModified\": n_modified}\n",
    "    return transaction_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = update_applicants(ds_app, observations_assigned)\n",
    "print(\"result type:\", type(result))\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Classes: Building the Repository\n",
    "\n",
    "We've managed to extract data from our database using our `find_by_date` function, transform it using our `assign_to_groups` function, and load it using our `update_applicants` function. Does that mean we're done? Not yet! There's an issue we need to address: distraction.\n",
    "\n",
    "What do we mean when we say distraction? Think about it this way: Do you need to know the exact code that makes `df.describe()` work? No, you just need to calculate summary statistics! Going into more details would distract you from the work you need to get done. The same is true of the tools you've created in this lesson. Others will want to use them in future experiments with worrying about your implementation. The solution is to **abstract** the details of your code away.\n",
    "\n",
    "To do this we're going to create a [Python class.](https://docs.python.org/3/tutorial/classes.html) Python classes contain both information and ways to interact with that information. An example of class is a pandas `DataFrame`. Not only does it hold data (like the size of an apartment in Buenos Aires or the income of a household in the United States); it also provides methods for inspecting it (like `DataFrame.head()` or `DataFrame.info()`) and manipulating it (like `DataFrame.sum()` or `DataFrame.replace()`). \n",
    "\n",
    "In the case of this project, we want to create a class that will hold information about the documents we want (like the name and location of the collection) and provide tools for interacting with those documents (like the functions we've built above). Let's get started!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a `MongoRepository` class with an `__init__` method. The `__init__` method should accept three arguments: `client`, `db`, and `collection`. Use the docstring below as a guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MongoRepository:\n",
    "     # Task 7.2.14\n",
    "    def __init__(self, client=MongoClient(host=\"localhost\", port=27017), db=\"wqu-abtest\",collection=\"ds-applicants\"):\n",
    "        self.collection = client[db][collection]\n",
    "\n",
    "    # Task 7.2.17\n",
    "    def find_by_date(self, date_string):\n",
    "        # Convert `date_string` to datetime object\n",
    "        start = pd.to_datetime(date_string, format='%Y-%m-%d')\n",
    "        # Offset `start` by 1 day\n",
    "        end = start + pd.DateOffset(days=1)\n",
    "        # Create PyMongo query for no-quiz applicants b/t `start` and `end`\n",
    "        query = {\"createdAt\": {\"$gte\": start, \"$lt\": end}, \"admissionsQuiz\": \"incomplete\"}\n",
    "        # Query collection, get result\n",
    "        result = self.collection.find(query)\n",
    "        # Convert `result` to list\n",
    "        observations = list(result)\n",
    "\n",
    "        return observations\n",
    "    # Task 7.2.18\n",
    "    def update_applicants(self, observations_assigned):\n",
    "        n = 0\n",
    "        n_modified = 0\n",
    "        #iterate through applicants\n",
    "        for doc in observations_assigned:\n",
    "            result = self.collection.update_one(\n",
    "                filter={\"_id\": doc[\"_id\"]},\n",
    "                update={\"$set\": doc}\n",
    "                )\n",
    "            #updated counter\n",
    "            n += result.matched_count\n",
    "            n_modified += result.modified_count\n",
    "        #create results\n",
    "        transaction_result = {\"n\": n, \"nModified\": n_modified}\n",
    "        return transaction_result\n",
    "    \n",
    "        # Task 7.2.19\n",
    "    def assign_to_groups(self, date_string):\n",
    "        #get Observation\n",
    "        observations = self.find_by_date(date_string)\n",
    "        \n",
    "        # Shuffle `observations`\n",
    "        random.seed(42)\n",
    "        random.shuffle(observations)\n",
    "        \n",
    "        # Get index position of item at observations halfway point\n",
    "        idx = len(observations) // 2                                        # ciel and floor\n",
    "\n",
    "        # Assign first half of observations to control group\n",
    "        for doc in observations[idx:]:\n",
    "            doc[\"inExperiment\"] = True\n",
    "            doc[\"group\"] = \"email (treatment)\" \n",
    "\n",
    "        # Assign second half of observations to treatment group\n",
    "        for doc in observations[:idx]:\n",
    "            doc[\"inExperiment\"] = True\n",
    "            doc[\"group\"] = \"email (control)\" \n",
    "        \n",
    "        result = self.update_applicants(observations)\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = MongoRepository()\n",
    "print(\"repo type:\", type(repo))\n",
    "repo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Extract the `collection` attribute from `repo`, and assign it to the variable `c_test`. Is the `c_test` the correct data type?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_test = repo\n",
    "print(\"c_test type:\", type(c_test))\n",
    "c_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(repo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our class is built, and now we need to take the ETL functions we created and turn them into **class methods**. Think back to the beginning of the course, where we learned how to work with DataFrames. If we call a DataFrame `df`, we can use methods designed by other people to figure out what's inside. We've learned lots of those methods already — `df.head()` `df.info()`, etc. — but we can also create our own. Let's give it a try."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using your function as a model, create a `find_by_date` method for your `MongoRepository` class. It should take only one argument: `date_string`. Once you're done, test your method by extracting all the users who created account on 15 May 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "may_15_users = repo.find_by_date(date_string=\"2022-05-15\")\n",
    "print(\"may_15_users type\", type(may_15_users))\n",
    "print(\"may_15_users len\", len(may_15_users))\n",
    "may_15_users[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using your function as a model, create an `update_applicants` method for your `MongoRepository` class. It should take one argument: `documents`. To test your method, use the function to update the documents in `observations_assigned`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = repo.update_applicants(observations_assigned)\n",
    "print(\"result type:\", type(result))\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Create an `assign_to_groups` method for your `MongoRepository` class. Note that it should work differently than your original function. It will take one argument: `date_string`. It should find users from that date, assign them to groups, update the database, and return the results of the transaction. Once you're done, use your method to assign all the users who created account on **14 May 2022**, to groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = repo.assign_to_groups(date_string=\"2022-05-15\")\n",
    "print(\"result type:\", type(result))\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
